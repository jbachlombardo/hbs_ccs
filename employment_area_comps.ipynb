{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>DATA IMPORTS</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_empl_17_threedigi = pd.read_csv('C:/Users/jbachlombardo/Documents/Community Colleges/Data/College scorecard/CollegeScorecard_Raw_Data/agged_empl_wages_by_county_THREE DIGIT_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "six_dig_naics = pd.read_csv('C:/Users/jbachlombardo/Documents/Community Colleges/Data/CIP NAICS Crosswalk_THREE DIGIT_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "naicscodes = [int(x) for x in six_dig_naics[['NAICS Code', 'NAICS Title']].drop_duplicates().dropna()['NAICS Code']]\n",
    "naicstitles = list(six_dig_naics[['NAICS Code', 'NAICS Title']].drop_duplicates().dropna()['NAICS Title'])\n",
    "naics_codes_to_titles = dict(zip(naicscodes, naicstitles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "unitid_degs_sixdig = pd.read_csv('C:/Users/jbachlombardo/Documents/Community Colleges/Data/IPEDS/six_deg_ccs_wpercs_no990 051419.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools = pd.read_csv('C:/Users/jbachlombardo/Documents/Community Colleges/Data/College scorecard/CollegeScorecard_Raw_Data/merged_all_scorecard_indicators_longitudinal_zips_fipsadj_RESET FROM HERE 051419_adjacents.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools = schools.replace('NaN', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:/Users/jbachlombardo/Documents/Community Colleges/Data/naics_degree_dictionary_THREEDIGIT_2.pickle', 'rb') as handle:\n",
    "    naics_deg_dict_THREEDIGIT = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>DEF FUNCTIONS</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_county(s, df_schools, df_employ, df_sixdig_degs, deg_dict) :\n",
    "    #PREP\n",
    "    school = df_schools.loc[df_schools['UNITID'] == s]\n",
    "    fips = school['FIPS'].item()\n",
    "    county = df_employ.loc[df_employ['FIPS'] == fips]\n",
    "    school_degs = school.merge(df_sixdig_degs, on = 'UNITID')\n",
    "    county['annual_avg_emplvl_%'] = county['annual_avg_emplvl'] / county['annual_avg_emplvl'].sum()\n",
    "    nonzero_jobs = list(county[county['annual_avg_emplvl'] > 0]['industry_code'].unique())\n",
    "    #CALCS\n",
    "    school_cols = list(school_degs.columns)\n",
    "    jobs_for_df = list()\n",
    "    employment_for_df = list()\n",
    "    degs_in_job_for_df = list()\n",
    "    for j in nonzero_jobs :\n",
    "        deg_list_cc = list()\n",
    "        for d in deg_dict[j] :\n",
    "            if str(int(d)) in school_cols :\n",
    "                deg_list_cc.append(str(int(d)) + '_%')\n",
    "        degs_produced = school_degs[deg_list_cc].sum(axis = 1).item()\n",
    "        makeup_deg_list = [deg[:-2] for deg in school_degs[deg_list_cc].dropna(axis = 1).columns]\n",
    "        jobs_for_df.append(j)\n",
    "        employment_for_df.append(degs_produced)\n",
    "        degs_in_job_for_df.append(makeup_deg_list)\n",
    "    #CLEANUP\n",
    "    job_comps = pd.DataFrame(data = {'Job': jobs_for_df, '% filled': employment_for_df, 'Degrees makeup': degs_in_job_for_df})\n",
    "    job_comps = job_comps.set_index('Job').merge(county[['industry_code', 'annual_avg_emplvl_%']].set_index('industry_code'), left_index = True, right_index = True)\n",
    "    job_comps['% surplus'] = job_comps['% filled'] - job_comps['annual_avg_emplvl_%']\n",
    "    job_comps['UNITID'] = s\n",
    "    job_comps = job_comps.reset_index().set_index('UNITID').rename(columns = {'index': 'NAICS Job Category'})\n",
    "    \n",
    "    return job_comps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_counties(s, df_schools, df_employ, df_sixdig_degs, deg_dict) :\n",
    "    #PREP\n",
    "    school = df_schools.loc[df_schools['UNITID'] == s]\n",
    "    counties_fips = literal_eval(schools.loc[schools['UNITID'] == s, 'ADJ_FIPS'].item())\n",
    "    school_degs = school.merge(df_sixdig_degs, on = 'UNITID')\n",
    "    counties = df_employ.loc[df_employ['FIPS'].isin(counties_fips)]\n",
    "    grouped_counties = counties.groupby('industry_code', as_index = False)['annual_avg_emplvl'].sum()\n",
    "    grouped_counties['annual_avg_emplvl_%'] = grouped_counties['annual_avg_emplvl'] / grouped_counties['annual_avg_emplvl'].sum()\n",
    "    nonzero_jobs = list(grouped_counties[grouped_counties['annual_avg_emplvl'] > 0]['industry_code'].unique())\n",
    "    #CALCS\n",
    "    school_cols = list(school_degs.columns)\n",
    "    jobs_for_df = list()\n",
    "    employment_for_df = list()\n",
    "    degs_in_job_for_df = list()\n",
    "    for j in nonzero_jobs :\n",
    "        deg_list_cc = list()\n",
    "        for d in deg_dict[j] :\n",
    "            if str(int(d)) in school_cols :\n",
    "                deg_list_cc.append(str(int(d)) + '_%')\n",
    "        degs_produced = school_degs[deg_list_cc].sum(axis = 1).item()\n",
    "        makeup_deg_list = [deg[:-2] for deg in school_degs[deg_list_cc].dropna(axis = 1).columns]\n",
    "        jobs_for_df.append(j)\n",
    "        employment_for_df.append(degs_produced)\n",
    "        degs_in_job_for_df.append(makeup_deg_list)\n",
    "    #CLEANUP\n",
    "    job_comps = pd.DataFrame(data = {'Job': jobs_for_df, '% filled': employment_for_df, 'Degrees makeup': degs_in_job_for_df})\n",
    "    job_comps = job_comps.set_index('Job').merge(grouped_counties[['industry_code', 'annual_avg_emplvl_%']].set_index('industry_code'), left_index = True, right_index = True)\n",
    "    job_comps['% surplus'] = job_comps['% filled'] - job_comps['annual_avg_emplvl_%']\n",
    "    job_comps['UNITID'] = s\n",
    "    job_comps = job_comps.reset_index().set_index('UNITID').rename(columns = {'index': 'NAICS Job Category'})\n",
    "  \n",
    "    return job_comps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_leftover_degs(s, df_job_comps, df_sixdig_degs) :\n",
    "    used = list()\n",
    "    for degs in df_job_comps['Degrees makeup'] :\n",
    "        if len(degs) > 0 :\n",
    "            for d in degs :\n",
    "                if d in used :\n",
    "                    continue\n",
    "                else :\n",
    "                    used.append(d)\n",
    "    leftover = [c for c in df_sixdig_degs.set_index('UNITID').loc[s].dropna().index if '_%' in c and c[:-2] not in used]\n",
    "    leftover_df = df_sixdig_degs.set_index('UNITID').loc[s][leftover].to_frame().T.reset_index().rename(columns = {'index': 'UNITID'})\n",
    "    \n",
    "    return leftover_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_job_comps(job_comps, deg_dict) :\n",
    "    job_comps.set_index('NAICS Job Category').sort_values(by = '% surplus')['% surplus'].plot(kind = 'barh', figsize = (4, 12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>SLIMMING TO NCES DATASET</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_schools = list(unitid_degs_sixdig['UNITID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools = schools[schools['UNITID'].isin(unique_schools)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>RUNNING COMPS</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_comps_all = pd.DataFrame()\n",
    "leftovers_all = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jbachlombardo\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "C:\\Users\\jbachlombardo\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n",
      "  \n",
      "C:\\Users\\jbachlombardo\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "for s in unique_schools :\n",
    "    if pd.isnull(schools.loc[schools['UNITID'] == s, 'ADJ_COUNTIES'].item()) :\n",
    "        job_comps = one_county(s, schools, current_empl_17_threedigi, unitid_degs_sixdig, naics_deg_dict_THREEDIGIT)\n",
    "    else :\n",
    "        job_comps = multiple_counties(s, schools, current_empl_17_threedigi, unitid_degs_sixdig, naics_deg_dict_THREEDIGIT)\n",
    "    leftovers = get_leftover_degs(s, job_comps, unitid_degs_sixdig)\n",
    "    job_comps_all = pd.concat([job_comps_all, job_comps])\n",
    "    leftovers_all = pd.concat([leftovers_all, leftovers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_comps_all.to_csv('C:/Users/jbachlombardo/Documents/Community Colleges/Data/job_comps 051419_990s removed.csv')\n",
    "leftovers_all.to_csv('C:/Users/jbachlombardo/Documents/Community Colleges/Data/leftovers 051419_990s removed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "leftovers_all = leftovers_all.set_index('UNITID')\n",
    "leftovers_all['Total leftover'] = leftovers_all.sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
